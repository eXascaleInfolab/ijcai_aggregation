%%%% ijcai19.tex

\typeout{Aggregation for open-ended task}

% These are the instructions for authors for IJCAI-19.

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in
% The file ijcai19.sty is NOT the same than previous years'
\usepackage{ijcai19}

% Use the postscript times font!
\usepackage{times}
\usepackage{soul}
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\urlstyle{same}
\usepackage[T1]{fontenc}
\usepackage{colortbl}
\usepackage{amsmath}
\usepackage{url}
\usepackage{xspace}
\usepackage[algo2e,titlenotnumbered,boxed,ruled,vlined,linesnumbered]{algorithm2e}
\newcommand{\sys}{****\xspace}
% the following package is optional:
%\usepackage{latexsym} 

% Following comment is from ijcai97-submit.tex:
% The preparation of these files was supported by Schlumberger Palo Alto
% Research, AT\&T Bell Laboratories, and Morgan Kaufmann Publishers.
% Shirley Jowell, of Morgan Kaufmann Publishers, and Peter F.
% Patel-Schneider, of AT\&T Bell Laboratories collaborated on their
% preparation.

% These instructions can be modified and used in other conferences as long
% as credit to the authors and supporting agencies is retained, this notice
% is not changed, and further modification or reuse is not restricted.
% Neither Shirley Jowell nor Peter F. Patel-Schneider can be listed as
% contacts for providing assistance without their prior permission.

% To use for other conferences, change references to files and the
% conference appropriate and use other authors, contacts, publishers, and
% organizations.
% Also change the deadline and address for returning papers and the length and
% page charge instructions.
% Put where the files are available in the appropriate places.

\title{\sys: Finding Influencers Using an Open-Ended Task}

% Single author syntax
\author{
    XI Lab
    \affiliations
    University of Fribourg, Switzerland\emails
    firstname.lastname@unifr.ch
}

% Multiple author syntax (remove the single-author syntax above and the \iffalse ... \fi here)
% Check the ijcai19-multiauthor.tex file for detailed instructions
\iffalse
\author{
First Author$^1$
\and
Second Author$^2$\and
Third Author$^{2,3}$\And
Fourth Author$^4$
\affiliations
$^1$First Affiliation\\
$^2$Second Affiliation\\
$^3$Third Affiliation\\
$^4$Fourth Affiliation
\emails
\{first, second\}@example.com,
third@other.example.com,
fourth@example.com
}
\fi
\newcommand{\iar}[1]{\textcolor{blue}{(*** @Ines: #1 ***)}}
\begin{document}

\maketitle

\begin{abstract}
\iar{write the abstract}
\end{abstract}

\section{Introduction}
Social influence is increasingly becoming a subtle force that controls the dynamics of the social network. 
Finding users in a network with a social influence is becoming a fundamental 
task for several applications such as brand marketing \cite{bond201261}
\cite{richardson2002mining} \cite{van2007new}, expert finding for question 
answering \cite{riahi2012finding} and collaborative task execution \cite{sun2014analyzing}\cite{miao2010generative}. These users are referred to as ``influencers"
and are recognized with a set properties such as a high number of 
followers, a regular feed about a certain topic and an ``authentic" content.
 Existing work tackles the problem from a network perspective where 
 several approaches have been proposed to find influencers by performing content analysis and/or link analysis. However, the task of finding influencers remains a challenging task as these influencers
exhibit several subjective properties such as the ``authenticity" of their
content. Such a property is hard to assess by machines nowadays.
The current techniques used to find influencers in a social network
can be broadly classified into two groups:
\begin{itemize}
\item User Classification: This method consists in measuring the influence of each user 
based on their content in social media.
Those satisfying a set of properties are classified as influencers (e.g 
number of followers higher than 1000)
\cite{Cheng2014} \cite{Lehmann2013}
 
\item Expert identification: While the user classification
problem have been extensively studied, they are still not as reliable
as experts. For example, Zalando (a fashion online retailer)
relies on an influencer platform named ``Collabary"\footnote{\url{https://www.collabary.com}} to identify influencers.
\end{itemize}

This paper represents a step towards bridging the gap between these two classes by leveraging 
human workers for influencers identification. 
As a matter of fact, workers are able to generate results as 
accurate as experts and as scalable as user classification methods.
We introduce a new technique called \sys
which combines social properties of a collected set of users with worker's reliability to identify influencers.
More specifically, we consider a task where the crowd is asked to name influencers in a predefined domain.
The collected answers contain both noisy and low-quality elements hence, it is important
to control the quality of these answers. This is a common problem in crowdsourcing 
and a lot of techniques have been proposed to address it.  A simple yet effective method is 
Majority Voting. This method infers the truth from the majority as it takes the answer given by the majority of 
workers. However, Majority Voting considers all workers equal while in reality workers have different reliabilities.
Several algorithms have been proposed to measure worker's reliability \cite{demartini2012zencrowd}
\cite{raykar2010learning} \cite{dawid1979maximum}. All these methods mainly focuses on three types of tasks
\cite{ZhengLLSC17}: decision-making task, single/multiple choice task or numeric tasks. In these tasks, the number of
possible answers is usually predefined for example, in decision-making tasks, the answer could be either True or False. 
However, our task is an open-ended task i.e. it requires content creation and the number of possible answers
 is very large therefore the aforementioned techniques do not apply. 

Assessing workers answers in this task is particularly challenging for several reasons:
First, each worker provides a set of users who could potentially be an influencer 
and distilling the real ``influencer" from this set is not trivial 
based solely on the properties extracted from social media as they exhibit subjective
properties.
Second, when a worker $w_{1}$ provide a set of influencers but does not include an 
influencer provided by worker $w_{2}$ there's no explicit disagreement between 
$w_{1}$ and $w_{2}$. As a matter of fact, not naming an influencer does not mean 
classifying her as not an influencer.  Third, the concept of worker's reliability in our case
do not only depend on their motivation to do the task but also on their knowledge about
influencers in a particular domain. 

To address these issues, this paper introduces an Expectation Maximization (EM) 
algorithm that learns from both worker's reliability and the influencer's properties.
We also extend our model with efficient parameter estimation via variational inference.
\iar{extend?}

 \sys make a number of key contributions including:
\begin{itemize}
\item  We introduce the problem of aggregating open-ended task for influencer finding
\item We also present an Expectation Maximization (EM)  for learning influencer's quality 
\item We show an extension of the method using Variational Inference (VI)
for learning worker's reliability in finding influencers of a specific domain leveraging their
social properties 
\item We conduct extensive experiments on real-world datasets, demonstrating that
our technique outperforms state of the art techniques
\end{itemize}
To the best of our knowledge, this work is the first to find inluencers from sparse and noisy 
crowd answers. Our proposed framework is a generic one applicable to any open-ended task
and in a variety of domains e.g natural language processing.

\section{Related Work}
In this section, we discuss relevant work on (a) Truth Inference and (b) user classification
in social media.
\iar{is there a difference between using the term aggregation and truth inference?
in such case which one is more correct in our case?}

\subsection{Aggregation Techniques }



\subsection{Social Influence Analysis}




\section{Method}

\subsection{Problem Statement}


\subsection{Model 1}

\subsection{Model 2}


\section{Experiments}

\subsection{Experimental Setup}

\subsection{Experiments about Model 1}

\subsection{Experiments about Model 2}

\section{Conclusion}



\section*{Acknowledgments}



%% The file named.bst is a bibliography style file for BibTeX 0.99c
\bibliographystyle{named}
\bibliography{ijcai19}

\end{document}

