%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experiments and Results}

\subsection{Experimental Setup}

\noindent\textbf{Datasets.} We consider the problem of finding social influencers in two domains: fashion and information technology (InfoTech). For both domains, we publish question-answering tasks in Figure Eight\footnote{\url{https://www.figure-eight.com}} and collect crowd workers' answers. Important statistics of these datasets are presented in Table~\ref{tab:datasets}. For both datasets, we randomly select 40\% of the candidate influencers and ask domain experts to label them. Our initial analysis reveals that 30.64\% and 32.78\%  of crowd answers in the fashion domain and the InfoTech domain respectively are true influencers. Considering the relatively large number of crowd answers collected in a short period of time ($<$10 hours for both Fashion and InfoTech), this result validates our assumption that crowdsourced open-ended question-answering provides an efficient way for finding social influncers. Moreover, the sparsity of the answer matrix (Table~\ref{tab:datasets}) and the high percentage of incorrect answers motivates the necessity of open-ended answer aggregation that takes into account worker reliability.

\begin{table}[!ht]
%\small
\centering \caption{Descriptive statistics of the
datasets.}\label{tab:datasets}
%\vspace{-0.05in}
\addtolength{\tabcolsep}{-1mm}
\begin{tabular}{lcccc}
\toprule
    Datasets &\#Cand. Infl. &\#Workers &\#Answers &Sparsity   \\\midrule
    Fashion & 890 & 250 & 1416  & 0.652 \\
    InfoTech & 1057 & 200 &1643 & 0.729 \\
\bottomrule
\end{tabular}
% \vspace{-0.1in}
\end{table}

\smallskip
\noindent\textbf{Comparison Methods.} Due to the lack of existing open-ended answer aggregation methods, we compare with the following state-of-the-art closed-pool answer aggregation methods: 1) LFC \cite{raykar2010learning}, EM method 
that incorporate priors into worker's model; 2) ZenCrowd \cite{demartini2012zencrowd}, EM method that estimates worker reliability as a model parameter; 3) Dawid-Skene \cite{dawid1979maximum}, EM method that learns worker reliability as a confusion matrix; 4) GLAD \cite{whitehill2009whose}, EM method that simutaneously learn worker reliability and task difficulty. To apply these methods to our problem, we use negative sampling to simulate workers' answers of non-influencers; we empirically find the optimal sampling rates for each comparison method. 

For \sys, we compare the following variants. a) LR: simplified \sys with only a logistic regression model trained on the labeled subset of candidate influencers for influencer classification; 2) NN: simplified \sys with only a multi-layer perceptron; 3) \sys-EM: \sys that further leverages worker answer matrix however models worker reliability as a fixed paramter; 4) \sys, the Bayesian version that models worker reliability as a latent variable.

\smallskip
\noindent\textbf{Parameter Settings.} The parameters of our framework and those for model training are empirically set. We search for the best model architecture for NN, and the predictor $f$ in \sys-EM and \sys with 0, 1, and 2 hidden layers, and apply a grid search in \{64, 128, 256, 512, 1024\} for the dimension of the hidden layers. In model training, we select learning rates from \{0.0001, 0.001, 0.01, 0.1, 1\} for the learning of $\mathbf{W}_I$ in all variants of our framework, as well as for the learning of $r_j$ in \sys-EM. To investigate the impact of negative sampling, we experiment with sampling rate ($s\_rate$) from \{0, 1, 5, 10, 20, 50, 100\} where $s\_rate=5$ indicates that for each worker, the negative samples is five times the size of the candidate influencers named by the worker. 

\smallskip
\noindent\textbf{Evaluation Protocols.} We split the labeled subset of candidate influencers into training, validation, and test sets. \sys is trained on the answer matrix and the training set, and evaluated on the test set. Validation set is used to search for the optimal parameter settings. To investigate the impact of the degree of supervision ($s\_deg$) on \sys performance, we split the labeled subset by $s\_deg\in \{50\%, 60\%, 70\%, 80\%, 90\%\}$, where $s\_deg = 60\%$ means that 60\% of the labeled subset is used for training, and the rest for validation and test with equal split.



\subsection{Results of \sys}
\label{sec:selfres}

\noindent\textbf{Results of \sys Variants.}
The performance of our four variants is depicted by Figure \ref{fig:variants}.
\sys-EM outperforms both LR and NN by 13.05\% and XX\% in accuracy
and by 3.435\% and XX\% in AUCPR  showing the effectiveness of both using
the worker reliability and social feature of influencers. \sys modeling the 
worker reliability as a Beta distribution, performs the best among the four variants
with 1.7\% lift in accuracy indicating the benefir of considering priors to worker's 
reliability.
\begin{figure}[htb]
\begin{subfigure}[t]{0.47\columnwidth}
        \centering
    \pgfplotstableread[row sep=\\,col sep=&]{
       cases & LR & NN & EM & VEM \\
       Fashion     &0.604166667  & 0.7006  & 0.7333 &0.7555  \\
       IT    & 0.511 & 0.6  & 0.641&0.647 \\
    }\mydata

    \begin{tikzpicture}[scale=0.5]
    \begin{axis}[
    ybar,
    bar width=.55cm,
    width=2\textwidth,
    height=1.5\textwidth,
    legend style={at={(0.67,1.2)},
       anchor=north,legend columns= 4, font = \LARGE},
    symbolic x coords={Fashion, IT},
    xtick=data,
    enlarge x limits=0.3,
    ymin=0.55,ymax=0.80,
    ylabel={Accuracy},
    yticklabel style = {font=\huge,xshift=0.5ex},
    xticklabel style = {font=\huge,yshift=0.5ex},
    ylabel style ={font = \huge},
    ymajorgrids=true
    ]
    \addplot[draw=gray,fill=gray!40!white, thick] table[x=cases,y=LR]{\mydata};
    \addplot[draw=blue,fill=blue!40!white] table[x=cases,y=NN]{\mydata};
    \addplot[draw=black,fill=black!50!white, thick] table[x=cases,y=EM]{\mydata};
    \addplot[draw=red,fill=red!40!white, thick] table[x=cases,y=VEM]{\mydata};
    \legend{LR, NN, EM, VEM}
    \end{axis}
    \end{tikzpicture}
    \vspace{-0.15in}
        \caption{Accuracy\label{fig:acc}} 
    \end{subfigure}% 
  \hfill \hskip -2.5ex %
    	\begin{subfigure}[t]{0.47\columnwidth}
        \centering
  \centering
    \pgfplotstableread[row sep=\\,col sep=&]{
       cases & LR & NN & EM & VEM \\
       Fashion     &0.235142445  & 0.2154  &0.277139619 &0.42670444  \\
       IT   &0.18673464  & 0.2154  & 0.2134 &0.2137 \\
    }\mydata

    \begin{tikzpicture}[scale=0.5]
    \begin{axis}[
    ybar,
    bar width=.55cm,
    width=2\textwidth,
    height=1.5\textwidth,
    legend style={at={(0.67,1.2)},
       anchor=north,legend columns= 4, font = \LARGE},
    symbolic x coords={Fashion, IT},
    xtick=data,
    enlarge x limits=0.3,
    ymin=0.2,ymax=0.5,
    ylabel={AUCPR},
    yticklabel style = {font=\huge,xshift=0.5ex},
    xticklabel style = {font=\huge,yshift=0.5ex},
    ylabel style ={font = \huge},
    ymajorgrids=true
    ]
    \addplot[draw=gray,fill=gray!40!white, thick] table[x=cases,y=LR]{\mydata};
    \addplot[draw=blue,fill=blue!40!white] table[x=cases,y=NN]{\mydata};
    \addplot[draw=black,fill=black!50!white, thick] table[x=cases,y=EM]{\mydata};
    \addplot[draw=red,fill=red!40!white, thick] table[x=cases,y=VEM]{\mydata};
    \legend{LR, NN, EM, VEM}
    \end{axis}
    \end{tikzpicture}
    \vspace{-0.15in}
        \caption{AUCPR\label{fig:aucpr}} 
    \end{subfigure}% 
   \caption{\sys performance} \label{fig:variants}
\end{figure}

\smallskip
\noindent\textbf{Benefits of Incorporating Confidence.}

\smallskip
\noindent\textbf{Impacts of Sampling Rate.}
\smallskip
\noindent\textbf{Impacts of Supervision Degree.}
\begin{figure}[htb]\centering
	\begin{subfigure}[t]{0.47\columnwidth}
\begin{tikzpicture}[scale=0.5]
\begin{axis}[
    xlabel={Sampling Rate},
    ylabel={Accuracy},
    xmin=0, xmax=100,
    ymin=0.6, ymax=0.8,
    xtick={0,20,40,60,80,100},
    ytick={0.6,0.65,0.7,0.75,0.8},
       legend style={at={(0.67,1.2)},
       anchor=north,legend columns= 4, font = \LARGE},
    yticklabel style = {font=\huge,xshift=0.5ex},
    xticklabel style = {font=\huge,yshift=0.5ex},
    ylabel style ={font = \huge},
    xlabel style ={font = \huge},
    ymajorgrids=true,
    grid style=dashed,
    width=2\textwidth,
    height=1.5\textwidth
]
\addplot[
    color=blue,
    mark=square,
    ]
    coordinates 
 {
    (0,0.594444444)
    (1,0.608333333)
    (5,0.611111111)
    (10,0.701388889)
    (20,0.698611111)
    (50,0.688888889)
    (80,0.699074074)
    (100,0.694444444)
    };
   \addplot plot coordinates {
            (0,   0.611111111)
            (1,   0.611111111)
            (5,  0.665277778)
            (10,  0.680555556)
            (20,  0.683333333)
            (50,  0.680555556)
             (80,  0.680555556)
             (100,  0.680555556)
        };   
\legend{EM,VEM}
\end{axis}
\end{tikzpicture}
    \vspace{-0.15in}
        \caption{Accuracy\label{fig:acc_sr}} 
 \end{subfigure}
 \begin{subfigure}[t]{0.47\columnwidth}
\begin{tikzpicture}[scale=0.5]
\begin{axis}[
    xlabel={Sampling Rate},
    ylabel={AUCPR},
    xmin=0, xmax=100,
    ymin=0.2, ymax=0.5,
    xtick={0,20,40,60,80,100},
    ytick={0.2,0.25,0.3,0.35,0.4,0.45,0.5},
       legend style={at={(0.67,1.2)},
       anchor=north,legend columns= 4, font = \LARGE},
    yticklabel style = {font=\huge,xshift=0.5ex},
    xticklabel style = {font=\huge,yshift=0.5ex},
    ylabel style ={font = \huge},
    xlabel style ={font = \huge},
    ymajorgrids=true,
    grid style=dashed,
    width=2\textwidth,
    height=1.5\textwidth
]
\addplot[
    color=blue,
    mark=square,
    ]
    coordinates 
 {
(0,	0.246639963	)
(1,	0.256483971	)
(5,	0.253552091	)
(10,	0.248987253)
(20,	0.314226928)
(50,	0.394545774	)
(80,	0.375925108	)
(100,	0.344059166	)
    };
   \addplot plot coordinates {
(0	,	0.362436935)
(1	,	0.386168629)
(5		,0.417435551)
(10	,	0.420309803)
(20	,0.440776769)
(50	,0.425099887)
(80	,	0.428685528)
(100	,0.429375752	)
        };   
\legend{EM,VEM}
\end{axis}
\end{tikzpicture}
    \vspace{-0.15in}
        \caption{AUCPR\label{fig:aucpr_sr}} 
 \end{subfigure}
  \label{fig:sys_perf} 
   \caption{Fashion dataset (supervision 60\%)}
\end{figure}

\begin{figure}[htb]\centering
	\begin{subfigure}[t]{0.47\columnwidth}
\begin{tikzpicture}[scale=0.5]
\begin{axis}[
    xlabel={Sampling Rate},
    ylabel={Accuracy},
    xmin=0, xmax=100,
    ymin=0.6, ymax=0.7,
    xtick={0,20,40,60,80,100},
    ytick={0.6,0.62,0.64,0.66,0.68,0.7},
       legend style={at={(0.67,1.2)},
       anchor=north,legend columns= 4, font = \LARGE},
    yticklabel style = {font=\huge,xshift=0.5ex},
    xticklabel style = {font=\huge,yshift=0.5ex},
    ylabel style ={font = \huge},
    xlabel style ={font = \huge},
    ymajorgrids=true,
    grid style=dashed,
    width=2\textwidth,
    height=1.5\textwidth
]
\addplot[
    color=blue,
    mark=square,
    ]
    coordinates 
 {
(0,	0.6125	)
(1,	0.640625)	
(5,	0.6328125)	
(10,	0.634375)	
(20,	0.6453125)	
(50,	0.6453125)	
(80,	0.6515625)	
(100, 0.663529412)			
    };
   \addplot plot coordinates {
(0	,	0.635416667)
(1	,	0.625)
(5,	0.619791667)
(10	,	0.675485009)
(20	,0.635416667)
(50	,	0.600694444)
(80	,	0.612847222	)	
(100,	0.612847222	)
        };   
\legend{EM,VEM}
\end{axis}
\end{tikzpicture}
    \vspace{-0.15in}
        \caption{Accuracy\label{fig:acc_sr_it}} 
 \end{subfigure}
 \begin{subfigure}[t]{0.47\columnwidth}
\begin{tikzpicture}[scale=0.5]
\begin{axis}[
    xlabel={Sampling Rate},
    ylabel={AUCPR},
    xmin=0, xmax=100,
    ymin=0.1, ymax=0.4,
    xtick={0,20,40,60,80,100},
    ytick={0.1,0.15,0.2,0.25,0.3,0.35},
         legend style={at={(0.67,1.2)},
       anchor=north,legend columns= 4, font = \LARGE},
    yticklabel style = {font=\huge,xshift=0.5ex},
    xticklabel style = {font=\huge,yshift=0.5ex},
    ylabel style ={font = \huge},
    xlabel style ={font = \huge},
    ymajorgrids=true,
    grid style=dashed,
    width=2\textwidth,
    height=1.5\textwidth
]
\addplot[
    color=blue,
    mark=square,
    ]
    coordinates 
 {
(0	, 0.23847869	)
(1,	0.26798091	)
(5,	0.260324331	)
(10,	0.306452047	)
(20,	0.222293649	)
(50,	0.274607103	)
(80,	0.248572165		)
(100,0.27161014)	
    };
   \addplot plot coordinates {
(0,		0.150767473)
(1	,	0.190113466)
(5	,	0.193542963)
(10,	0.329383407)
(20,	0.199531136)
(50,	0.170545745)
(80,	0.174072684)
(100,	0.179211754)
        };   
\legend{EM,VEM}
\end{axis}
\end{tikzpicture}
 \caption{AUCPR\label{fig:aucpr_sr_it}} 
 \end{subfigure}
  \label{fig:sys_perf} 
   \caption{IT dataset (supervision 70\%)}
\end{figure}

\subsection{Comparative Results}
\begin{table*}[!h]
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|l|}
\hline
\multicolumn{2}{|l|}{Dataset}          & \multicolumn{5}{c|}{Fashion}          & \multicolumn{5}{c|}{IT}               \\ \hline
\multicolumn{2}{|l|}{Supervision rate} & 50\%  & 60\%  & 70\%  & 80\%  & 90\%  & 50\%  & 60\%  & 70\%  & 80\%  & 90\%  \\ \hline
\multirow{2}{*}{DS}          & acc     & 0.689 & 0.716 & 0.703 & 0.688 & 0.711 & 0.662 & 0.660 & 0.626 & 0.641 & 0.536 \\ \cline{2-12} 
                             & auprc   & 0.191 & 0.169 & 0.242 & 0.244 & 0.263 & 0.174 & 0.203 & 0.222 & 0.255 & 0.272 \\ \hline
\multirow{2}{*}{GLAD}        & acc     & 0.697 & 0.716 & 0.724 & 0.700 & 0.688 & 0.669 & 0.667 & 0.637 & 0.672 & 0.595 \\ \cline{2-12} 
                             & auprc   & 0.183 & 0.189 & 0.229 & 0.224 & 0.263 & 0.150 & 0.186 & 0.138 & 0.219 & 0.307 \\ \hline
\multirow{2}{*}{ZC}          & acc     & 0.701 & 0.686 & 0.733 & 0.702 & 0.688 & 0.651 & 0.674 & 0.664 & 0.683 & 0.627 \\ \cline{2-12} 
                             & auprc   & 0.157 & 0.175 & 0.203 & 0.239 & 0.287 & 0.146 & 0.198 & 0.212 & 0.246 & 0.234 \\ \hline
\multirow{2}{*}{OpenCrowd}   & acc     & 0.724 & 0.733 & 0.725 & 0.733 & 0.75  & 0.673 &   0.674  &   0.662     &     0.672   &   0.686    \\ \cline{2-12} 
                             & auprc   & 0.265 & 0.277 & 0.273 & 0.299 & 0.388  &  0.207     &   0.213    &  0.267     &  0.300  &  0.333 \\ \hline
\end{tabular}
\end{table*}
\label{sec:compres}